{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I do a few tests to analyze how racial demographics are correlated with income in New York City neighborhoods. I have placed census tract-level economic and social demographic data from the 2015 American Community Survey (ACS) into a MySQL table called \"acs2015\" in a database called \"nyc.\" To analyze the data, I will be using PySpark.\n",
    "\n",
    "Because I want to gain insights about how race and income are related, I will be mostly using simple models. Simpler models typically are less flexible and so may not give the strongest results, but they are often much easier to interpret.\n",
    "\n",
    "Some things I use in this notebook:\n",
    "\n",
    "  - PySpark\n",
    "  - Spark SQL\n",
    "  - Reading MySQL tables with Spark\n",
    "  - SQL groupBy\n",
    "  - SQL queries\n",
    "  - Linear regression\n",
    "  - K-Means clustering\n",
    "  - k-Fold cross validation\n",
    "  \n",
    "As usual, we start by initializing the SparkContext and SQLContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc = SparkContext('local[2]','Tutorial')\n",
    "sql = SQLContext(sc)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will use the JDBC (Java mysql connector) driver to read the database from the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs2015 = sql.read.format('jdbc').options(\n",
    "    url = 'jdbc:mysql://localhost/nyc',\n",
    "    driver = \"com.mysql.jdbc.Driver\",\n",
    "    dbtable = \"acs2015\",\n",
    "    user=\"\",\n",
    "    password=\"\").load()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the table in a DataFrame format.\n",
    "\n",
    "printSchema() will show us the table schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CensusTract: long (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- TotalPop: long (nullable = true)\n",
      " |-- Men: long (nullable = true)\n",
      " |-- Women: long (nullable = true)\n",
      " |-- Hispanic: double (nullable = true)\n",
      " |-- White: double (nullable = true)\n",
      " |-- Black: double (nullable = true)\n",
      " |-- Native: double (nullable = true)\n",
      " |-- Asian: double (nullable = true)\n",
      " |-- Citizen: long (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      " |-- IncomeErr: double (nullable = true)\n",
      " |-- IncomePerCap: double (nullable = true)\n",
      " |-- IncomePerCapErr: double (nullable = true)\n",
      " |-- Poverty: double (nullable = true)\n",
      " |-- ChildPoverty: double (nullable = true)\n",
      " |-- Professional: double (nullable = true)\n",
      " |-- Service: double (nullable = true)\n",
      " |-- Office: double (nullable = true)\n",
      " |-- Construction: double (nullable = true)\n",
      " |-- Production: double (nullable = true)\n",
      " |-- Drive: double (nullable = true)\n",
      " |-- Carpool: double (nullable = true)\n",
      " |-- Transit: double (nullable = true)\n",
      " |-- Walk: double (nullable = true)\n",
      " |-- OtherTransp: double (nullable = true)\n",
      " |-- WorkAtHome: double (nullable = true)\n",
      " |-- MeanCommute: double (nullable = true)\n",
      " |-- Employed: long (nullable = true)\n",
      " |-- PrivateWork: double (nullable = true)\n",
      " |-- PublicWork: double (nullable = true)\n",
      " |-- SelfEmployed: double (nullable = true)\n",
      " |-- FamilyWork: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acs2015.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have added information such as income, total population, racial demographics, work and commute types, job categories, and more. We can look at a few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CensusTract=36005000100, County='Bronx', Borough='Bronx', TotalPop=7703, Men=7133, Women=570, Hispanic=29.9, White=6.1, Black=60.9, Native=0.2, Asian=1.6, Citizen=6476, Income=None, IncomeErr=None, IncomePerCap=2440.0, IncomePerCapErr=373.0, Poverty=None, ChildPoverty=None, Professional=None, Service=None, Office=None, Construction=None, Production=None, Drive=None, Carpool=None, Transit=None, Walk=None, OtherTransp=None, WorkAtHome=None, MeanCommute=None, Employed=0, PrivateWork=None, PublicWork=None, SelfEmployed=None, FamilyWork=None, Unemployment=None),\n",
       " Row(CensusTract=36005000200, County='Bronx', Borough='Bronx', TotalPop=5403, Men=2659, Women=2744, Hispanic=75.8, White=2.3, Black=16.0, Native=0.0, Asian=4.2, Citizen=3639, Income=72034.0, IncomeErr=13991.0, IncomePerCap=22180.0, IncomePerCapErr=2206.0, Poverty=20.0, ChildPoverty=20.7, Professional=28.7, Service=17.1, Office=23.9, Construction=8.0, Production=22.3, Drive=44.8, Carpool=13.7, Transit=38.6, Walk=2.9, OtherTransp=0.0, WorkAtHome=0.0, MeanCommute=43.0, Employed=2308, PrivateWork=80.8, PublicWork=16.2, SelfEmployed=2.9, FamilyWork=0.0, Unemployment=7.7),\n",
       " Row(CensusTract=36005000400, County='Bronx', Borough='Bronx', TotalPop=5915, Men=2896, Women=3019, Hispanic=62.7, White=3.6, Black=30.7, Native=0.0, Asian=0.3, Citizen=4100, Income=74836.0, IncomeErr=8407.0, IncomePerCap=27700.0, IncomePerCapErr=2449.0, Poverty=13.2, ChildPoverty=23.6, Professional=32.2, Service=23.4, Office=24.9, Construction=9.0, Production=10.5, Drive=41.3, Carpool=10.0, Transit=44.6, Walk=1.4, OtherTransp=0.5, WorkAtHome=2.1, MeanCommute=45.0, Employed=2675, PrivateWork=71.7, PublicWork=25.3, SelfEmployed=2.5, FamilyWork=0.6, Unemployment=9.5)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs2015.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Census tracts contain fairly consistent numbers of people, so we should see how many tracts we get in each of the five boroughs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|      Borough|count|\n",
      "+-------------+-----+\n",
      "|       Queens|  669|\n",
      "|     Brooklyn|  761|\n",
      "|Staten Island|  110|\n",
      "|    Manhattan|  288|\n",
      "|        Bronx|  339|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acs2015.groupBy('Borough').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Brooklyn and Queens have the most. The Bronx actually has more tracts than Manhattan despite having a smaller population, but I would imagine that this is mostly due to the fact that Manhattan has a much higher population density.\n",
    "\n",
    "We can use the pyspark.sql.functions package to look at aggregate functions such as the median household income of the wealthiest and poorest neighborhoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(Income)|\n",
      "+-----------+\n",
      "|   244375.0|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|min(Income)|\n",
      "+-----------+\n",
      "|     9829.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sqlf\n",
    "\n",
    "acs2015.agg(sqlf.max('Income')).show()\n",
    "acs2015.agg(sqlf.min('Income')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running SQL Queries in PySpark\n",
    "\n",
    "We can create a temp view of the DataFrame. This lets us run SQL queries on the DataFrame, which will make it much easier to create clean DataFrames. Here, I will look at things such as the total population and average income of tracts that have a majority of people in one of the four major racial categories, \"White,\" \"Black,\" \"Hispanic,\" or \"Asian.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acs2015.createOrReplaceTempView('ACS2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 406\n",
      "+-------------+-----+\n",
      "|      Borough|count|\n",
      "+-------------+-----+\n",
      "|       Queens|   86|\n",
      "|     Brooklyn|   65|\n",
      "|Staten Island|    2|\n",
      "|    Manhattan|   41|\n",
      "|        Bronx|  212|\n",
      "+-------------+-----+\n",
      "\n",
      "+-------------+\n",
      "|sum(TotalPop)|\n",
      "+-------------+\n",
      "|      1893465|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Income)|\n",
      "+-----------------+\n",
      "|36691.77306733167|\n",
      "+-----------------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Income)|\n",
      "+-----------------+\n",
      "|59101.32079961923|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sql.sql('SELECT * from ACS2015 WHERE hispanic>50')\n",
    "print('Count ' +str(df.count()))\n",
    "df.groupBy('Borough').count().show()\n",
    "df.agg(sqlf.sum('TotalPop')).show()\n",
    "df.agg(sqlf.mean('Income')).show()\n",
    "acs2015.agg(sqlf.mean('Income')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority Hispanic are most common in the Bronx and contain 1.9 million residents. These areas have an average income nearly 40% lower than the overall average income tract. Note that the averages here are not weighted by the number of residents, so this is not the same as the true average income for the city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 454\n",
      "+-------------+-----+\n",
      "|      Borough|count|\n",
      "+-------------+-----+\n",
      "|       Queens|  118|\n",
      "|     Brooklyn|  253|\n",
      "|Staten Island|    3|\n",
      "|    Manhattan|   27|\n",
      "|        Bronx|   53|\n",
      "+-------------+-----+\n",
      "\n",
      "+-------------+\n",
      "|sum(TotalPop)|\n",
      "+-------------+\n",
      "|      1617139|\n",
      "+-------------+\n",
      "\n",
      "+------------------+\n",
      "|       avg(Income)|\n",
      "+------------------+\n",
      "|51464.282222222224|\n",
      "+------------------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Income)|\n",
      "+-----------------+\n",
      "|59101.32079961923|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sql.sql('SELECT * from ACS2015 WHERE black>50')\n",
    "print('Count ' +str(df.count()))\n",
    "df.groupBy('Borough').count().show()\n",
    "df.agg(sqlf.sum('TotalPop')).show()\n",
    "df.agg(sqlf.mean('Income')).show()\n",
    "acs2015.agg(sqlf.mean('Income')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority black areas are most common in Brooklyn. They contain 1.6 million residents and have an average income around 13% lower than the city average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 711\n",
      "+-------------+-----+\n",
      "|      Borough|count|\n",
      "+-------------+-----+\n",
      "|       Queens|  158|\n",
      "|     Brooklyn|  288|\n",
      "|Staten Island|   74|\n",
      "|    Manhattan|  158|\n",
      "|        Bronx|   33|\n",
      "+-------------+-----+\n",
      "\n",
      "+-------------+\n",
      "|sum(TotalPop)|\n",
      "+-------------+\n",
      "|      2764109|\n",
      "+-------------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Income)|\n",
      "+-----------------+\n",
      "|80105.03299856528|\n",
      "+-----------------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Income)|\n",
      "+-----------------+\n",
      "|59101.32079961923|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sql.sql('SELECT * from ACS2015 WHERE white>50')\n",
    "print('Count ' +str(df.count()))\n",
    "df.groupBy('Borough').count().show()\n",
    "df.agg(sqlf.sum('TotalPop')).show()\n",
    "df.agg(sqlf.mean('Income')).show()\n",
    "acs2015.agg(sqlf.mean('Income')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority white areas are common in every borough except the Bronx and contain 2.8 million residents. Their average income is about 1/3 higher than the city average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count 100\n",
      "+---------+-----+\n",
      "|  Borough|count|\n",
      "+---------+-----+\n",
      "|   Queens|   70|\n",
      "| Brooklyn|   22|\n",
      "|Manhattan|    8|\n",
      "+---------+-----+\n",
      "\n",
      "+-------------+\n",
      "|sum(TotalPop)|\n",
      "+-------------+\n",
      "|       429648|\n",
      "+-------------+\n",
      "\n",
      "+-----------+\n",
      "|avg(Income)|\n",
      "+-----------+\n",
      "|   51281.32|\n",
      "+-----------+\n",
      "\n",
      "+-----------------+\n",
      "|      avg(Income)|\n",
      "+-----------------+\n",
      "|59101.32079961923|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sql.sql('SELECT * from ACS2015 WHERE asian>50')\n",
    "print('Count ' +str(df.count()))\n",
    "df.groupBy('Borough').count().show()\n",
    "df.agg(sqlf.sum('TotalPop')).show()\n",
    "df.agg(sqlf.mean('Income')).show()\n",
    "acs2015.agg(sqlf.mean('Income')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, majority Asian areas appear mainly in Queens and contain 400,000 residents. The average income there is very similar to the majority black areas, at around 13% below the average census tract.\n",
    "\n",
    "So, if we consider areas with a majority of people from a single racial category, there are large differences in the average income depending on the racial category. These areas also contain roughly 3/4 of all NYC residents. This does make it appear that race has a strong correlation to income (although I haven't looked at things like the standard deviations). \n",
    "\n",
    "If we want to understand how a tract's racial demographics correlate with its income, linear regression would be a good first model.\n",
    "\n",
    "# Income Prediction with Linear Regression\n",
    "\n",
    "Linear regression is quite simple and generally easy to understand. If we don't add any polynomial features and just use the fraction of residents from each racial category, the coefficients tell us how much we expect the income to change as we alter the demographics of an area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will first get rid of null values. Then, I need to package the features as a Vector, which can be done with the VectorAssembler. I will only use three features: the percentage of residents identifying as black, Hispanic, and Asian. The sum of these three and the percentage of white residents is almost always very close to 100, so including all four would not really tell us any more information and might make it harder to find a good maximum. With this choice, the intercept tells us a \"baseline\" income for a nearly all-white neighborhood, and the coefficients tell us how each racial minority category changes the income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs2015 = acs2015.where(acs2015['Income'].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = VectorAssembler(inputCols=['Black','Hispanic','Asian'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding the \"features\" column, we may as well drop the other columns that we're not going to need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CensusTract: long (nullable = true)\n",
      " |-- County: string (nullable = true)\n",
      " |-- Borough: string (nullable = true)\n",
      " |-- TotalPop: long (nullable = true)\n",
      " |-- Men: long (nullable = true)\n",
      " |-- Women: long (nullable = true)\n",
      " |-- Hispanic: double (nullable = true)\n",
      " |-- White: double (nullable = true)\n",
      " |-- Black: double (nullable = true)\n",
      " |-- Native: double (nullable = true)\n",
      " |-- Asian: double (nullable = true)\n",
      " |-- Citizen: long (nullable = true)\n",
      " |-- Income: double (nullable = true)\n",
      " |-- IncomeErr: double (nullable = true)\n",
      " |-- IncomePerCap: double (nullable = true)\n",
      " |-- IncomePerCapErr: double (nullable = true)\n",
      " |-- Poverty: double (nullable = true)\n",
      " |-- ChildPoverty: double (nullable = true)\n",
      " |-- Professional: double (nullable = true)\n",
      " |-- Service: double (nullable = true)\n",
      " |-- Office: double (nullable = true)\n",
      " |-- Construction: double (nullable = true)\n",
      " |-- Production: double (nullable = true)\n",
      " |-- Drive: double (nullable = true)\n",
      " |-- Carpool: double (nullable = true)\n",
      " |-- Transit: double (nullable = true)\n",
      " |-- Walk: double (nullable = true)\n",
      " |-- OtherTransp: double (nullable = true)\n",
      " |-- WorkAtHome: double (nullable = true)\n",
      " |-- MeanCommute: double (nullable = true)\n",
      " |-- Employed: long (nullable = true)\n",
      " |-- PrivateWork: double (nullable = true)\n",
      " |-- PublicWork: double (nullable = true)\n",
      " |-- SelfEmployed: double (nullable = true)\n",
      " |-- FamilyWork: double (nullable = true)\n",
      " |-- Unemployment: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "race_data = vectorizer.transform(acs2015)\n",
    "race_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Income: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "race_data = race_data.select('Income','features')\n",
    "race_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're ready to run a linear regression model. I will optimize the regularization parameters, although it will turn out to not be very important.\n",
    "\n",
    "Because I have not rescaled the features or the income, we will need a large regularization parameter to have much of an effect. In the Spark LinearRegression model, there are two parameters: An overall regularization strength parameter and another to give the balance between L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "lr = LinearRegression(featuresCol='features',\n",
    "                      labelCol='Income',\n",
    "                      predictionCol='prediction',\n",
    "                      maxIter=50,\n",
    "                      regParam=0.2,\n",
    "                      elasticNetParam=0.5)\n",
    "\n",
    "(training, test) = race_data.randomSplit([0.8,0.2],seed=234)\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam,[10,50,100,300,500,1000]) \\\n",
    "                              .addGrid(lr.elasticNetParam,[0.0,0.2,0.5,0.8,1]).build()\n",
    "    \n",
    "evaluator = RegressionEvaluator(metricName='r2',\n",
    "                                labelCol='Income',\n",
    "                                predictionCol='prediction')\n",
    "\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                   estimatorParamMaps=paramGrid,\n",
    "                   evaluator=evaluator,\n",
    "                   numFolds=5)\n",
    "\n",
    "mod = cv.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg: 10 ElNet: 0.0 R2: 0.38\n",
      "Reg: 10 ElNet: 0.2 R2: 0.38\n",
      "Reg: 10 ElNet: 0.5 R2: 0.38\n",
      "Reg: 10 ElNet: 0.8 R2: 0.38\n",
      "Reg: 10 ElNet: 1 R2: 0.38\n",
      "Reg: 50 ElNet: 0.0 R2: 0.38\n",
      "Reg: 50 ElNet: 0.2 R2: 0.38\n",
      "Reg: 50 ElNet: 0.5 R2: 0.38\n",
      "Reg: 50 ElNet: 0.8 R2: 0.38\n",
      "Reg: 50 ElNet: 1 R2: 0.38\n",
      "Reg: 100 ElNet: 0.0 R2: 0.38\n",
      "Reg: 100 ElNet: 0.2 R2: 0.38\n",
      "Reg: 100 ElNet: 0.5 R2: 0.3799\n",
      "Reg: 100 ElNet: 0.8 R2: 0.3799\n",
      "Reg: 100 ElNet: 1 R2: 0.3799\n",
      "Reg: 300 ElNet: 0.0 R2: 0.3799\n",
      "Reg: 300 ElNet: 0.2 R2: 0.3798\n",
      "Reg: 300 ElNet: 0.5 R2: 0.3797\n",
      "Reg: 300 ElNet: 0.8 R2: 0.3795\n",
      "Reg: 300 ElNet: 1 R2: 0.3793\n",
      "Reg: 500 ElNet: 0.0 R2: 0.3797\n",
      "Reg: 500 ElNet: 0.2 R2: 0.3795\n",
      "Reg: 500 ElNet: 0.5 R2: 0.3791\n",
      "Reg: 500 ElNet: 0.8 R2: 0.3786\n",
      "Reg: 500 ElNet: 1 R2: 0.3781\n",
      "Reg: 1000 ElNet: 0.0 R2: 0.3789\n",
      "Reg: 1000 ElNet: 0.2 R2: 0.3782\n",
      "Reg: 1000 ElNet: 0.5 R2: 0.3766\n",
      "Reg: 1000 ElNet: 0.8 R2: 0.3744\n",
      "Reg: 1000 ElNet: 1 R2: 0.3725\n"
     ]
    }
   ],
   "source": [
    "vals = mod.avgMetrics\n",
    "pars = mod.getEstimatorParamMaps()\n",
    "\n",
    "for v,p in zip(vals,pars):\n",
    "    r = list(p.values())[0]\n",
    "    e = list(p.values())[1]\n",
    "    \n",
    "    print('Reg: {} ElNet: {} R2: {:0.4}'.format(r,e,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that less regularization is giving us better results. However, even at a regularization parameter of 1000, there is not much degradation in performance.\n",
    "\n",
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-425.213390301,-770.430232518,-425.814647839]\n",
      "Intercept: 95708.11321806749\n"
     ]
    }
   ],
   "source": [
    "print('Coefficients: '+str(mod.bestModel.coefficients))\n",
    "print('Intercept: '+str(mod.bestModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our fit shows an intercept of $95,708. This would be the expected income of an all-white neighborhood. It is also very high, perhaps skewed by extremely wealthy parts of Manhattan.\n",
    "\n",
    "We see that the three linear coefficients are all negative. As the fraction of ethnic/racial minorities increases, the expected income falls. For both Asian and black populations, the expected income drops by $425 for every percent increase. Hispanic areas are the poorest, with the income dropping by $770 for every percent increase.\n",
    "\n",
    "But, how has our model performed on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on Test Set 0.333\n"
     ]
    }
   ],
   "source": [
    "testpred = mod.transform(test)\n",
    "r2 = evaluator.evaluate(testpred)\n",
    "print('R2 on Test Set {:0.4}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an $R^2$ score of 0.33 here, somewhat smaller than the 0.38 that we expected from the cross validation. We didn't look at the individual cross validation numbers for the 5 folds, but it's fairly likely that this is well within the expected range.\n",
    "\n",
    "An $R^2$ score of 0.33 shows that there likely is a correlation but it's not particularly strong. Racial demographics are only able to explain 1/3 of the variance in incomes between census tracts. Race is correlated with many other factors, so if we were to add more features, we might expect race to have a smaller effect.\n",
    "\n",
    "We also only used basic linear features. The effect may be nonlinear, so adding more features even based just on our current set could give us a higher $R^2$ (in fact it must, which is why things like the adjusted $R^2$ exist). The disadvantage is that it becomes more difficult to interpret the numbers.\n",
    "\n",
    "# Income Prediction with K-Means Clustering\n",
    "\n",
    "Our linear regression model showed that we can find some correlation between race and income, but race alone can only explain maybe 1/3 of the variation. Another simple way that we could use to predict income is to use unsupervised learning techniques to split the data into clusters and then use the average income of each cluster as the predicted value.\n",
    "\n",
    "The cluster properties may tell us about different sorts of neighborhoods that exist in the city. This cluster method is actually not so different from a decision tree regressor, but trained in an unsupervised manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is in the right format, the Spark K-Means clustering class is pretty straightforward to use. I've just set K=10, but some optimization can obviously be done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set RMSE: 11.54\n"
     ]
    }
   ],
   "source": [
    "km = KMeans().setK(10).setSeed(456)\n",
    "model = km.fit(training)\n",
    "err = np.sqrt(model.computeCost(training)/training.count())\n",
    "transformed = model.transform(training)\n",
    "transformed_test = model.transform(test)\n",
    "print('Within Set RMSE: {:0.4}'.format(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've trained the data, we should look at some information about our clusters.\n",
    "\n",
    "In K-Means, the clusters are defined by their center positions. We will also look at the count of tracts in each cluster to make sure that they look reasonably balanced, and finally, we will look at the mean income of tracts in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tCluster Centers\n",
      "White/\n",
      "Other\tBlack\tHisp.\tAsian\tNum\tIncome\n",
      "8.99\t31.7\t55.6\t3.68\t134\t31689.8\n",
      "56.1\t7.13\t28.2\t8.48\t162\t67940.6\n",
      "6.36\t82.4\t9.37\t1.88\t253\t56959.5\n",
      "31.7\t3.59\t19.1\t45.6\t106\t58261.2\n",
      "81.2\t2.48\t9.07\t7.28\t328\t85770.2\n",
      "15.7\t2.66\t12.0\t69.6\t57\t49392.1\n",
      "56.0\t5.09\t12.8\t26.1\t193\t72991.9\n",
      "10.9\t12.3\t71.5\t5.38\t193\t38460.5\n",
      "16.9\t52.6\t24.9\t5.59\t184\t43174.2\n",
      "23.0\t5.28\t43.8\t27.9\t107\t50418.8\n"
     ]
    }
   ],
   "source": [
    "centers = model.clusterCenters()\n",
    "\n",
    "inc = transformed.groupby('prediction') \\\n",
    "           .agg(sqlf.avg('Income') \\\n",
    "           .alias('Income')) \\\n",
    "           .sort(sqlf.col('prediction')).collect()\n",
    "num = transformed.groupby('prediction').count() \\\n",
    "                 .sort(sqlf.col('prediction')) \\\n",
    "                 .collect()\n",
    "print('\\tCluster Centers')\n",
    "print('White/')\n",
    "print('Other\\tBlack\\tHisp.\\tAsian\\tNum\\tIncome')\n",
    "for i,center in enumerate(centers):\n",
    "    n = num[i]['count']\n",
    "    income = inc[i].Income\n",
    "    \n",
    "    w = 100 - center[0]-center[1]-center[2]\n",
    "    print('{:0.3}\\t{:0.3}\\t{:0.3}\\t{:0.3}\\t{}\\t{:0.6}'\n",
    "          .format(w,center[0],center[1],center[2],n,income))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the smallest cluster has 57 tracts and the largest has 328, with most in the 100-200 range. We can immediately see a few things:\n",
    "\n",
    "The smallest and two largest clusters have large majorities from a single racial group. The three majority-white clusters have by far the highest incomes.\n",
    "\n",
    "The poorest cluster is nearly 90% black and Hispanic, while the next smallest is similar but also over 70% Hispanic. \n",
    "\n",
    "There are only two clusters where no racial category has a majority but no clusters where the typical tract has even just 10% or more residents from each of the four categories.\n",
    "\n",
    "To make predictions, we need to take the predicted cluster and map it onto the income. Then, we can just run a RegressionEvaluator. The create_map() function is able to take a dictionary and then give us the mapped values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "theMap = {}\n",
    "for idx,income in enumerate(inc):\n",
    "    theMap[idx] = income.Income\n",
    "mapper = sqlf.create_map( [sqlf.lit(p) for p in chain(*theMap.items())])\n",
    "tfd = transformed_test.withColumn('PredInc',mapper.getItem(sqlf.col('prediction')))\n",
    "tfd_train = transformed.withColumn('PredInc',mapper.getItem(sqlf.col('prediction')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Income from KMeans\n",
      "Training R2: 0.3675\n",
      "Test R2: 0.3371\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(metricName='r2',\n",
    "                                labelCol='Income',\n",
    "                                predictionCol='PredInc')\n",
    "r2_train = evaluator.evaluate(tfd_train)\n",
    "r2 = evaluator.evaluate(tfd)\n",
    "print('Predicting Income from KMeans')\n",
    "print('Training R2: {:0.4}'.format(r2_train))\n",
    "print('Test R2: {:0.4}'.format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that this unsupervised model gives us essentially equivalent results as the linear regression classifier. It might be interesting to see what kinds of tracts do better with each regressor. If the results are different enough, perhaps something like a boosted decision tree model would be able to give us much better results.\n",
    "\n",
    "# Conclusions\n",
    "\n",
    "We've looked at how racial demographics in New York City appear to be related to income. From two different analyses, we've found that we can explain around 1/3 of the variation between different census tracts using racial demographics. So, while race does seem to be correlated with income, it is not the dominant factor explaining income levels. Our data set includes other useful information that we could add to the analysis or analyze separately, such as the kinds of jobs workers from each tract have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
